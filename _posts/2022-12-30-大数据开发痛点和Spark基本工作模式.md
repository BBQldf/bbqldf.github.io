---
layout:     post
title:     大数据开发和Spark基本工作模式
subtitle:   大数据介绍、Spark运行模式
date:       2023-02-14
author:     ldf
header-img: img/post-bg-spark03.png
catalog: true
tags:
    - Spark
---
# 大数据开发和Spark基本工作模式

# 一、大数据开发

## 1、 大数据分析业务痛点在哪？

1. Java Web中日志数据(一般是json格式，而且数据量非常大)存储在哪里？（肯定不是mysql）

2. 如何统计歌曲实时热度和歌手实时热度？（注意是实时的，sql是否还支持快速）

3. 点播日志中没有歌手信息怎么办？（sql的连表查询？）

4. 使用VUE开发WEB实时展示结果？（不需要，VUE强调交互，大数据展示只用更新数据即可）

5. 实施点播展示一直轮询数据库？（是的）数据量大效率低怎么办？（mysql数据库量如果超过2000w条，无论是加了索引还是别的）

## 2、 构建大数据平台最重要的一环是？

1. 构建数据仓库（进一步地，考虑数据孤岛，redis效率这些）

 

## 3、 Java Web为什么需要大数据？

1. 场景1：（单单这些**数据量的存储**就已经遇到了瓶颈；且涉及多个业务库）
   - 抖音平台：点赞、评论、私信、广告、浏览记录、商品数据、交易订单

2. 场景2：（这些类型的数据需要二次加工，除了查询，还存在计算**瓶颈**）
   -  电影网站：“热播榜单”、“喜剧榜单”、“动作榜单”、周、月度排行

3. 场景3：（这种场景如果在Java Web中运转，需要多个微服务之间协调；数**据传递性能较低**）
   -   实时交易：实时统计人数？电商交易金额？

4. 场景4：（**数据挖掘有局限**；大数据有一套成熟的推荐机制，比Java Web实现起来更简单）
   -  京东、淘宝、当当做产品推荐？



# 二、Spark运行模式

Spark遵循主(Master) -- 从(slave)工作模式，它有四类运行角色：

- Master角色,管理整个集群的资源——>类比于YARN的ResouceManager
- Worker角色,管理单个服务器的资源——>类比于YARN的NodeManager
- Driver角色，管理单个Spark任务在运行的时候的工作——>类比于YARN的ApplicationMaster
- Executor角色,单个任务运行的时候的一堆工作者,干活的——>类比于YARN的容器内运行的TASK。（在local模式下，driver可以即管理又干活）



它的运行模式包括Local、Standalone、Yarn、Kubernetes及Mesos几种。其中Local模式仅用于本地开发，Mesos模式国内几乎不用（AMPLab开发的，后在Twitter得到广泛使用）。

- 本地模式（单机）——开发和测试
  - 本地模式就是以一个独立的进程 ，**通过其内部的多个线程**来模拟整个Spark运行时环境
- Standalone模式（集群）——生产
  - Spark中的各个角色以独立进程的形式存在，并组成Spark集群环境
- Hadoop YARN模式（集群）——生产
  - Spark中的各个角色运行在YARN的容器内部，并组成Spark集群环境
- Kubernetes模式（集群）——生产
  - Spark中的各个角色运行在Kubernetes的容器内部，并组成Spark集群环境

## 2.1详解Standalone模式:

> Standalone模式是Spark内置的运行模式，常用于小型测试集群。

1、Master为资源调度器，负责executors资源调度

2、Worker负责Executor进程的启动和监控

3、Driver在客户端启动，负责SparkContext初始化



## 2.2 详解Yarn模式:

在公司中因为大数据服务基本搭载Yarn集群调度，因此Spark On Yarn模式会用的比较多：



## 2.3 谈谈Yarn Cluster和Yarn Client模式的区别

> 一道典型的面试题。从广义上讲，yarn-cluster适用于生产环境；而yarn-client适用于交互和调试，也就是希望快速地看到application的输出。

yarn-cluster和yarn-client存在区别的本质是因为一个组件：**ApplicationMaster**。在YARN中，每个Application实例都有一个Application Master进程，它的作用主要是，负责与ResourceManager协商资源，有了资源之后，就通知NodeManager要启动container，并和NodeManager协同来执行和监控Container。

**yarn-cluster模式下，**

- Driver首先作为一个ApplicationMaster在YARN集群中（任意一个NodeManager上）启动，客户端提交给ResourceManager的每一个job都会在集群的worker节点上分配一个唯一的ApplicationMaster，由该ApplicationMaster管理全生命周期的应用
- 因为Driver程序在YARN中运行，所以事先不用启动Spark Master/Client；所以应用的运行结果不能在客户端显示（可以在history server中查看），所以最好将结果保存在HDFS而非stdout输出
- Spark ApplicationMaster直接和container（executor）进行交互，完成这个分布式任务

**yarn-client模式下，**

- **Driver运行在Client上**，通过ApplicationMaster向RM获取资源
- 客户端的Driver将应用提交给Yarn后，Yarn会先后启动ApplicationMaster和executor
- 本地Driver负责与所有的executor进行交互，并将最后的结果汇总
- 一般来说，**如果运行的结果仅仅返回到terminal上时需要配置这个**



所以，在功能表现上，有这样几个区别：

1. SparkContext初始化不同，这也导致了Driver所在位置的不同，YarnCluster的Driver是在集群的某一台NodeManager上，但是Yarn-Client就是在client机器上
2. 而Driver会和Executors进行通信，这也导致了Yarn_cluster在提交App之后可以关闭Client，而Yarn-Client不可以
3. 应用场景，Yarn-Cluster适合生产环境，因为无法和client交互，而Yarn-Client模式下，client会和请求的container通信来调度他们工作，适合交互和调试
4. 日志获取：Yarn-Clien只能通过Applicationid获取日志



## 2.4 Spark是怎么解决主备切换的时候“不影响正在运行的程序”？——Spark HA高可用的原理

> Spark是怎么解决主备切换的时候“不影响正在运行的程序”？（例如：一个程序运行需要15h，运行到10h时master崩掉后切换到standby进程）

参考：1. https://blog.csdn.net/qq_34993631/article/details/86493860

​    Spark Master的主备切换可以基于两种切换机制，一种是文件系统，一种是基于Zookeeper,基于文件系统的机制，是Active Master挂掉后，需要我们手动去切换到Standby Master上，基于Zookeeper机制，以实现自动切换。

1. StandBy的Master使用持久化引擎（比如ZookeeperPersisitenceEngine）去读取storedApps，storedDriver，storedWorks。如果他们三个中有一个不为空那么就继续走下面的流程。

2. 将持久化的Application，Driver，Worker的信息进行再次注册，注册到缓存结构中（本质上是一个Map集合）。

3. 将Application与Worker的状态修改为UNKOWN。然后Master向Application的Driver以及对应的Worker发送自己的地址。

4. 这些Application与Driver在收到地址之后会发送响应给Master。这时Master就会调用自己的completeRecovery()方法来过滤掉没有给自己发送响应的Driver与Worker。

5. 最后Master就会调用自己的schedule()方法来对正在等待队列中等待的Driver与Application进行调度。比如在某个Worker上启动Driver,或者为Application在Worker上启动Executor。

![](https://raw.githubusercontent.com/BBQldf/PicGotest/master/20230214234434.png)





> 查漏补缺：Spark为什么这么快？
>
> 1. 除了是基于内存的运算模型，还有shuffle过程优化，和Mapreduce的shuffle过程中间文件频繁落盘不同，Spark对Shuffle机制进行了优化，降低中间文件的数量并保证内存优先。
> 2. RDD计算模型。Spark具有高效的DAG调度算法，同时将RDD计算结果存储在内存中，避免重复计算。



# 三、补充知识

## 1、Kafka的消息确认机制了解吗？

有两个地方会用到ack确认机制

1. producer发送消息至topic端ack确认

2. consumer从topic中消费消息ack确认

**生产者**发送消息的确认机制，**通过配置生产者acks实现**

- acks = 0：生产者根本不会等待服务器的任何确认。消息将立即添加到套接字缓冲区并视为已发送。这种情况下不能保证服务器已经收到消息，为每条记录返回的偏移量将始终设置为-1
- acks = 1：领导者副本会将消息写入其本地日志，并在不等待所有追随者完全确认同步到消息的情况下做出响应。如果领导者在确认消息后但在追随者复制它之前立即失败，消息将丢失
- acks = all / acks = -1 ：领导者将等待副本同步队列的所有副本确认收到消息。这保证只要至少一个同步副本保持活动状态，消息就不会丢失
- 默认设置为all

ISR机制：Leader维护了一个动态的in-sync replica set (ISR)，意为和leader保持同步的follower集合。follower长时间不同步，被踢出ISR ，该时间阈值由replica.lag.time.max.ms参数设定。Leader发生故障之后，就会从ISR中选举新的leader。

**消费者从topic中消费消息ack确认（两类）：**

```
//开启自动提交offset
props.put("enable.auto.commit", "true");
//自动提交offset延迟时间
props.put("auto.commit.interval.ms", "1000");
```

自动提交offset问题：没法控制消息是否正常被消费，适合不是重要的消息，例如日志采集 我们也可以设置为手动提交，代码示例如下（这里是异步提交）：

```
  consumer.commitAsync(new OffsetCommitCallback() {

    @Override

    public void onComplete(Map<TopicPartition, OffsetAndMetadata> offsets, Exception exception) {

     if (exception==null){

        System.out.println("手工提交offset成功:"+offsets.toString());

     }else{

        System.out.println("手工提交offset失败:"+offsets.toString());

     }

   }

  });
```

手动提交（同步提交）：

//同步提交，失败了会一直重试，会阻塞当前线程

consumer.commitSync();

## 2、kafka的副本机制为什么不像MySQL那样允许追随者副本也对外提供读服务

1. MySQL从库提供读服务，实现了读负载，减轻主库的读压力；而kafka的broker以及分区分配规则已经实现了多台broker的负载均衡

2. kafka保存的数据和数据库数据实质的区别就是kafka数据具有消费的概念，消费需要位移，而数据库是实体数据不存在这个概念，如果从kafka的follower读，消费者offset控制将会更复杂

3. 如果从follower读，就要确保领导者收到生产者的消息之后，follower也必须同步数据才不会造成副本间数据的不一致性，按照kafka设置的消息确认机制，那就必须需要等所有的追随者副本数据同步之后才是真正的消息确认，可能比acks = all的情况还需要更长的时间

## 3、Spark数据倾斜的解决方案有哪些？

首先，产生数据倾斜的主要原因是在shuffle过程中，不同的key对应的数据量不同，从而导致不同的task所分配的数据量不均匀。要解决数据倾斜的问题，可以从以下几个方面去考虑：

1. 提高shuffle操作的并行度。用户只要直接去增加shuffle读task的数量，比如设置reduceByKey[1000]，一般默认设置是200.
   - 优点：有效缓解数据倾斜
   - 缺点：无法彻底解决数据倾斜

2. 使用随机数前缀进行Join操作。对大量相同的key进行附加随机数前缀，让他变成不同的key；再将处理后不同的key分散到不同的task去处理
   - 优点：对Json类型的数据倾斜大多可以处理
   - 对内存要求比较高

3. 对Reduce join转换为Map join。适用于将两张表join时，一张表的数据量比较小的情况。通过将小表全量广播，然后通过map算子来实现与join相同的效果
   - 优点：不会发生shuffle
   - 缺点：只适用于大表加小表

4. 过滤少数导致数据倾斜的key。该方法的前提条件是，少数几个数据量特别多的key对任务的执行影响不大，可以直接通过where语句将他过滤掉
   - 优点：实现简单
     - 对包含少数几个数据量过大的key的那个RDD，通过sample算子采样出一份样本来，然后统计一下每个key的数量，计算出来数据量最大的是哪几个key
     - 然后将这几个key对应的数据从原来的RDD中拆分出来，形成一个单独的RDD，并给每个key都打上n以内的随机数作为前缀，而不会导致倾斜的大部分key形成另外一个RDD
     - 接着将需要join的另一个RDD，也过滤出来那几个倾斜key对应的数据并形成一个单独的RDD，将每条数据膨胀成n条数据，这n条数据都按顺序附加一个0~n的前缀，不会导致倾斜的大部分key也形成另外一个RDD
     - 再将附加了随机前缀的独立RDD与另一个膨胀n倍的独立RDD进行join，此时就可以将原先相同的key打散成n份，分散到多个task中去进行join了
     - 而另外两个普通的RDD就照常join即可
     - 最后将两次join的结果使用union算子合并起来即可，就是最终的join结果
   - 缺点：受限于特定场景

5. 使用Hive预处理数据。

6. 使用两阶段聚合操作。groupBy分组等场景，先通过局部预聚合，再通过全局聚合（这个和加随机数的方案类似。局部聚合时就是先给每个key都打上一个随机数，比如10以内的随机数，此时原先一样的key就变成不一样的了）
   - 优点：显著提升spark性能
   - 缺点：受限于固定场景

更多信息，可以参考：https://tech.meituan.com/2016/05/12/spark-tuning-pro.html

摘自tech.meituan: 大多数Spark作业的性能主要就是消耗在了shuffle环节，因为该环节包含了大量的磁盘IO、序列化、网络数据传输等操作。因此，如果要让作业的性能更上一层楼，就有必要对shuffle过程进行调优。但是也必须提醒大家的是，影响一个Spark作业性能的因素，主要还是代码开发、资源参数以及数据倾斜，shuffle调优只能在整个Spark的性能调优中占到一小部分而已。因此大家务必把握住调优的基本原则，千万不要舍本逐末。下面我们就给大家详细讲解shuffle的原理，以及相关参数的说明，同时给出各个参数的调优建议。
