---
layout:     post
title:      Hey Alexa,is this Skill Safe?Taking a Closer Look at the Alexa Skill Ecosystem
subtitle:   Diogo Barradas, Nuno Santos, Lu´ıs Rodrigues, Salvatore Signorelloy, Fernando M. V. Ramos, Andr´e Madeira
date:       2021-01-17
author:     Transliteration
header-img: img/post-bg-alexa.png
catalog: true
tags:
    - research
    - IoT
    - attacks 
---
	
	
	
> NDSS2021
# Abstract

亚马逊的语音助手Alexa使用户能够通过自然语言对话与各种网络服务直接互动。它为开发者提供了创建第三方应用程序（称为技能）的选择，以便在Alexa之上运行。虽然这类应用缓解了用户与智能设备的互动，并加强了一些额外的服务，但由于其运行的个人环境，它们也引起了安全和隐私问题。本文旨在对Alexa技能生态系统进行系统分析。我们对Alexa技能进行了首次大规模的分析，这些技能来自七个不同的技能商店，总共有90,194个独特的技能。我们的分析揭示了当前技能审查过程中存在的几个局限性。我们表明，恶意用户不仅可以在任何任意的开发者/公司名下发布技能，而且还可以在批准后修改后台代码，以哄骗用户透露不需要的信息。接下来，我们将不同的技能盗用(skillsquatting)技术正规化，并评估这些技术的功效。我们发现，虽然某些方法比其他方法更有利，但在现实世界中并没有大量滥用技能蹲守的情况。最后，我们研究了不同类别技能的隐私政策的普遍性，更重要的是研究了使用Alexa权限模型来访问敏感用户数据的技能的政策内容。我们发现，大约23.3%的此类技能没有完全披露与所要求的权限相关的数据类型。最后，我们提供了一些建议，以加强整个生态系统，从而提高最终用户的透明度。

# introduction
鉴于亚马逊Echo的市场定位是在家里使用，而且它们的麦克风是持续开启的，使用基于语音的第三方应用程序会引起隐私问题。研究表明，参与者知道他们私人住宅的信息被分享或披露给第三方，会感到不舒服[40], [16], [36]。此外，最近的研究继续显示对自动语音识别系统[46]、[20]、[21]和Alexa技能[56]的攻击越来越复杂。当Alexa与其他智能家居物联网设备（如智能锁或智能汽车）集成时1，就会产生安全问题。攻击者可以通过欺骗用户，简单地调用听起来与真实技能非常相似的技能，来扩大她的攻击矢量。例如，"lincoln way"（真实技能）和 "lincoln weigh"（虚构的恶意技能）听起来完全一样，但有可能欺骗Alexa激活错误的技能，从而使攻击者能够解锁用户的汽车。由于Alexa目前的政策是自动启用与调用短语相匹配的技能，攻击者有可能增加她发起成功攻击的几率。

## 主要回答三个问题：
**RQ1: What limitations exist in the current skill vetting process? **
For this we thoroughly analyze the various steps involved in registering a skill, and identify potential flaws in the overall system. 
**RQ2: How effective are skill squatting attacks?** 
To address this question, we not only scan the skill stores to identify skills with phonetically similar invocation names, but also propose a semi-automated approach to test which skills Alexa actually activate when presented with potentially squatted skills. 
**RQ3: Is the requirement of providing a privacy policy link effective? **
Alexa mandates a privacy policy link for skills that request certain permission APIs. We study the prevalence of privacy policies in different skill stores and analyze whether privacy policy links actually serve their purpose of informing users of their data practices. 

[Alexa skills store](https://www.amazon.com/b?node=13727921011&ref=sr_ex_n_1)

# contribution
一个恶意的行为者可以很容易地获得通常通过权限模型保护的敏感信息，通过语音界面向终端用户明确请求这些信息。我们还看到，攻击者可以对后端代码进行隐蔽的修改，以哄骗用户透露认证过程中从未调用过的信息。有趣的是，我们还看到攻击者可以使用知名的开发者名字来注册技能，这一点可以进一步帮助对手发动网络钓鱼攻击。接下来，我们发现了一些技能蹲守的证据，但在大多数情况下，**这种尝试是故意的，而不是恶意的，即开发者蹲守自己的技能，以提高技能被Alexa激活的机会。**最后，我们看到只有一小部分技能真正链接了隐私政策，即使是 "儿童 "和 "健康 "类别下的技能，这种情况也没有改善，根据现有的法规，如COPPA[1]、CCPA[48]和GDPR[2]，这些技能通常会引起更多关注。
* 我们对七个技能商店（美国、英国、澳大利亚、加州、德国、日本、法国）的Alexa技能进行了首次大规模分析。我们将我们的数据提供给研究界作进一步分析。
* 我们彻底分析了亚马逊的技能认证过程，并确定了几个潜在的漏洞，这些漏洞可以被恶意行为者利用来发布欺骗性技能。我们还提出了收紧此类漏洞的准则。
* 我们确定了用于蹲守技能的常见技术，包括以前没有讨论过的一种技术。我们还设计了一个半自动的方法来衡量各种技能蹲点技术的有效性。我们发现，虽然有些方法比其他方法更成功，但在野外并没有实质性的恶意滥用，有时我们会看到一个开发者蹲下她自己的技能来提高覆盖率。
* 最后，我们分析了技能的隐私政策内容。平均只有24.2%的技能提供了隐私政策链接，"孩子 "类别的技能是最大的违规者之一。当对比技能权限与隐私政策时，我们发现23.3%的政策没有正确处理与相应权限相关的请求数据类型。

# RELATED WORK
**Attacks on speech recognition systems.** Carlini等人[20]证明了输入音频是如何被合成的，以至于人类无法理解，但却被设备解释为命令。在后续的研究中，Carlini等人[21]正式确定了一种针对Mozilla DeepSpeech构建对抗性音频的技术，成功率为100%。Vaidya等人[51]在改变输入信号以适应目标转录方面也同样成功。最近，Yuan等人[53]表明，这种隐藏的语音命令可以很容易地嵌入到歌曲中而不被人类听众注意。心理声学模型也被用来操纵声学信号，使之成为人类无法感知的信号[46]。Abdullah等人[5]能够利用语音处理系统（VPSecs）常用的信号处理算法的知识，成功生成隐藏的语音命令。此外，一系列独立的研究表明，通过调制超声波载体上的隐藏命令，有可能发起听不见的语音攻击[54]，[47]，[43]。然而，攻击大多局限于实验室环境，很少在空中发挥作用，攻击是通过直接将音频样本输入ASR模型来评估的。

**Attacks on skills.** Edelman等人[27]率先发现了数千个在知名网站上有轻微排版变化的域名，这种做法通常被称为 "排版占用"。他们的发现激发了一系列测量和缓解域名抢注威胁的研究[31], [42], [6], [50], [33]。同样地，语音抢占攻击也被证明是可行的，因为Alexa技能。Kumar等人[35]首次表明，当两个不同技能的调用名称发音相似时，可以发起技能蹲点攻击。Zhang等人[55]最近介绍了一种新的技能蹲点攻击的变种，攻击者可以使用解析的调用名称来劫持合法技能。这种攻击是基于这样的观察，即Alexa在处理语音命令时倾向于最长的匹配技能名称。在另一项同时进行的工作中，Zhang等人[56]设计了一个语言学模型引导的模糊工具，以系统地发现Alexa技能中的语义不一致之处（已有防御）。他们指出，开发者控制的后端可以被开发者滥用，例如用恶意的音频文件替换合法的音频文件。然而，他们没有提供细节，也没有演示如何实现这一点。

**Prevalence of privacy policy.** 除了技术上的攻击载体来渗出用户数据或代表他们执行命令外，还有一种可能性是技能本身可以试图欺骗用户暴露敏感数据。法律规定要求公司向用户提供关于他们如何处理个人数据以及出于何种目的的信息。隐私政策已经成为获取数据实践信息的最重要来源。自从欧盟的《通用数据保护条例》（GDPR）出台后，隐私政策对于遵守法律要求的重要性有所增加[2]。Degeling等人[25]最近的一项研究表明，隐私政策在网站中的普及率已经上升到85%，而不仅仅限于欧盟。然而，一些研究表明，隐私政策所陈述的内容与所访问的数据之间存在不一致[17]。例如，Libert[38]发现，从网站流向第三方（如跟踪和分析服务）的信息，只有15%在网站的隐私政策中披露。早些时候，Zimmeck等人[58]表明，尽管大多数应用程序要求获得至少一个权限，使其能够访问个人数据，Google Play商店中的48%的应用程序没有隐私政策。2017年，Alhadlaq等人[8]对Alexa技能（当时约有10,000个技能）进行了小规模分析，发现75%的技能没有隐私政策，70%的现有政策没有提到任何具体的Alexa。（policy这里不作为未来研究方向，因为它往往涉及到app权限的分配，以及数据的使用，和具体的攻击和后续的处理有关，需要政策防控，而不是碎片化技术的追踪；但是它确实可以作为文章的必要性写上去）

## Distinction from prior work：
![table 1-system compare](https://raw.githubusercontent.com/BBQldf/markdownimgs/main/BBQimgs/ndss21-heyalexa/1.png)
1. 我们强调了后端代码可以被更新以触发休眠意图的方法，这可以欺骗用户放弃敏感数据--这在以前是没有被讨论或证明的。
2. Zhang等人[56]指出，攻击者可以交换后端音频文件，但没有提供简明的细节，而我们则展示了（通过发布技能）攻击者如何注册敏感数据类型的休眠意图（dormant intents）（第五节C）。我们还展示了攻击者如何使用知名的开发者名称（如Ring、Withings、Samsung）注册技能，欺骗用户启用钓鱼技能（第五节）。
3. 我们还进一步进行了大规模的经验分析，以总结在野外观察到的潜在的技能盗用技术/模式；现有的文献[55]，[35]主要集中在展示一种特定的方法如何导致技能盗用。我们还使用了一种半自动的方法来确定不同蹲守模式的功效--这是现有文献没有评估的（第六节）。
4. 最后，我们研究技能隐私政策。虽然，Alhadlaq等人[8]提供了隐私政策可用性的概述，但我们的工作比他们的分析大八倍，涵盖了他们的概述所遗漏的类别（例如，儿童）。此外，虽然之前的工作在可用性方面停止了分析，但我们是第一个强调潜在的 COPPA 违反、隐私政策授权的执行不足、许可与政策的不一致，以及显示模板导致潜在违反监管要求的根本原因分析（第七节）。我们相信，这些发现是对先前工作的重大贡献。

# 网页数据(skills)收集
基本的方案还是网络爬虫
![网页数据收集](https://raw.githubusercontent.com/BBQldf/markdownimgs/main/BBQimgs/ndss21-heyalexa/2.png)
使用Python对HTML文件进行解析，以提取有关每个技能的标题、调用名称、所需权限、隐私政策链接、评级和其他细节的信息（图2所示为一个技能的主页示例）。我们尊重亚马逊的 "Robots.txt "限制，只下载技能信息页面。但我们的尝试仍不时受到亚马逊API保护机制的限制（不到1%的请求），我们被重定向到一个 "机器人检查 "网站；我们在等待几分钟后下载了每个这样的页面。这些数据可供研究界进一步分析[4]。（“A privacy & security analysis of the Alexa skill ecosystem,” 2020. [Online]. Available: https://www:alexa-skill-analysis:org/）


<font size=5 color=red>介绍了信息收集，我筛选了一下本文的重点，比较有意思的几个攻击方案</font>

#LOOPHOLES IN SKILL VETTING
## 重复的技能调用名称
在美国的技能商店里，我们发现有9948个技能与至少一个其他技能共享相同的调用名称。在所有技能商店中，我们只发现了36,055个具有独特调用名称的技能。这使得当用户按名称安装一个技能时，他们得到他们想要的技能变得更加重要。自动启用技能意味着第三方开发者现在可以针对某些技能，用相同的调用短语注册新技能。例如，如果你要求 " space facts"，有81个这样的技能，亚马逊会自动选择其中一个。
（所以说语音蹲只是一种攻击方式而已，AWS采用了更加宽泛的技能名称策略）

然后这篇文章利用实验详细分析了aws的技能调用模块面临的重名风险。

## 利用知名的id来发布skills
我们能够使用 "Microsoft"、"Samsung"、"Ring "和 "Withings "作为开发者名称成功注册技能。然而，我们试图用 "飞利浦 "这个开发者的名字来注册一项技能，却被标记为使用第三方商标/品牌的潜在侵权行为。这告诉我们，没有一致的方法来检测以不同公司名称注册的技能。主要是，这是不同员工对技能进行人工审核的结果，其中一名员工能够发现我们的欺诈性注册企图。（核心原因还是人工审查导致的，缺陷已经很明显了，但是怎么利用还是个问题？）

## 已审核的技能进行代码变更以逃过检查
**后端代码在认证过程后可以随时改变**
![后端代码在认证过程后可以随时改变](https://raw.githubusercontent.com/BBQldf/markdownimgs/main/BBQimgs/ndss21-heyalexa/3.png)
图5强调了攻击者如何利用这一漏洞来欺骗用户提供敏感信息的总体流程图。首先，攻击者遵循所有注册技能的一般步骤（步骤1-3），但插入一个或多个通常在良性情况下保持休眠的意图（即，后台逻辑不会指导用户触发此类意图）。一旦技能被发布，攻击者就会改变后端逻辑，使用户调用休眠的意图，这可能对应于某种形式的敏感信息，如电话号码（步骤4-6）。我们开发了自己的技能来测试这种方法，我们建立了一个旅行规划师技能，要求用户创建一个旅行日程（B07N72MF9T）。在技能发布和测试后，我们改变了作为Lambda服务托管的后台代码，询问用户的电话号码，以便技能可以直接发送短信（SMS）行程。请注意，在最初的认证过程中，我们没有询问用户的电话号码，因此当亚马逊审核时，我们减少了被标记为通过他们指定的许可API请求电话号码的机会。还有很多其他的场景可以利用这个漏洞。例如，针对儿童的对话技能在获得他们的信任后，可以引诱他们透露家庭或个人生活的细节（假设用户的反应可以触发技能的最初认证意图）。

## 绕过权限系统
Alexa技能可以被配置为请求权限，以便从Alexa账户访问个人信息，如用户的地址或联系信息。（如果需要使用某项权限，需要提前进行询问，与手机app一致）

**亚马逊依赖于开发者对使用权限API的声明，而不是验证一个意图的数据类型本身。这样，开发者就可以绕过亚马逊关于在使用个人数据时提供隐私政策的要求。**这样，开发者就可以绕过亚马逊关于在使用个人数据时提供隐私政策的要求

***一个发现：***其实说实话，对于应用商店的技能去分析，现在回过头来看并不是多么高效的一个工作，因为他往往涉及到重复的技能，并且这么技能的实际应用如何也是未知，尽管他可能声明了一些权限；而且这里面发布的app是否还继续存在也是个问题，可能是“僵尸”技能。当热这也为攻击留下了窗口

在对候选人进行人工审核后，我们发现总共有358个独特的技能可能会要求提供受许可API保护的信息。接下来，为了消除任何剩余的误报，我们手动激活了这358个技能，以确定它们是否真的请求受权限API保护的数据类型。表六显示了不使用专用权限API而访问数据的实际技能数量。我们可以看到，绝大部分技能都是以口头方式请求数据的（总共166个技能）。然而，相当一部分技能也没有功能，其中要么是可以调用但后台服务器没有响应，要么是在商店里已经不存在了。

# skills squatting
## Common Approaches for Squatting Skills
![similarityscores](https://raw.githubusercontent.com/BBQldf/markdownimgs/main/BBQimgs/ndss21-heyalexa/4.png)
使用以下三种流行的语音算法生成每个调用名称的语音编码：Soundex [41]、metaphone [34] 和 nysiis [19]。然后我们计算了语音编码之间的列文斯坦距离[37]，以确定调用名称之间的相似性。我们还计算了所有调用对之间的通用列文斯坦距离。图6显示了调用名称之间的相似度的CDF。
（上面已经提供了几个平台可以分析语音编码的相似性了，能不能搞一个专有的检测工具？？感觉很有搞头，而且没在这个领域用用过，而且对于检测语音蹲攻击很有用啊！！并且对比方案都给出来了。。。）

大多数调用名称的相似性分数在[0.2, 0.4]的范围内。然而，为了检测潜在的语音争夺技能，我们把重点放在高度相似的配对上。因此，我们只考虑平均相似度为≥0:96的调用对，并将其标记为潜在的蹲守尝试（potential squatting attempts）。我们发现了338个这样的调用对。接下来，**我们手动分析了这些调用名称对，**以过滤那些发音完全不同的调用名称对（例如，"github stats "和 "github status"；"indiana facts "和 "indian facts"）。我们最终发现了85个实例，我们将其归类为潜在的蹲坑尝试。
四种常见的技能蹲点模式是:
* 同音字homophones
*标点符号punctuation
*间隔(或拆分单词)spacing
*不同的拼写（包括拼写错误） different spellings（spell variant）。

**findings：**虽然我们发现了四种常见的抢占现有技能的方法，但我们没有发现在野外有任何系统性的恶意滥用技能抢占的行为。恶意抢占技能的非证据对研究界来说是一个有价值的数据点，因为以前的工作都集中在展示技能如何被抢占，而没有验证现实世界中的普遍性和影响。然而，应该注意的是，未被发现的原因可能是由于亚马逊颁布的缓解策略，这可能是受到先前工作的影响。

**findings：**每个技能蹲点模式中的某些方法有更高的成功蹲点技能的可能性。对于不同的拼写类型和同音字，我们看到正确的/被接受的拼写比其带有额外或改变的字母的变体增加了启动预期技能的可能性。然而，对于标点符号的适当使用减少了其被激活的机会。而对于单词的间距，联合单词在大多数情况下都能成功。

# PRIVACY POLICY ANALYSIS OF SKILLS
亚马逊让技能开发者提供一个隐私政策链接，解决如何收集和使用来自最终用户的数据。然而，亚马逊并不强制要求所有技能都有隐私政策，而只是要求访问其一个或多个许可API的技能。
！[number of skills]()

首先分析了美国技能商店中的隐私政策链接的可用性。我们发现约有28.5%的美国技能提供了隐私政策链接（见表九），这与Alhadlaq等人[8]早在2017年的报告相似，当时他们发现11827项技能中约有25%的技能提供了隐私政策链接。我们发现，在所有提供政策链接的技能中，约有2.9%的技能在美国的技能商店中无法找到。我们甚至发现一个技能（B07DZT5YX9）的政策链接指向 "file://"，引用了开发者本地机器上的一个文件。这表明，Alexa有时没有正确审查隐私政策链接。

在请求某种形式的权限的1464项美国技能中，有41项没有提供政策链接，因为他们请求的是通知或提醒权限。对于剩下的1423项技能，我们发现有1285项技能（90%）提供了一个与隐私政策相关的内容的链接发布。我们手动审核了所有这些隐私政策，用于本分析。

然而，这样的过程是可以自动化的，为了证明这一点，**我们设计了一个分类器来确定隐私政策链接的内容是否真的提到了隐私政策。**我们手动审查了1000个Android隐私政策[57]和1000个从博客网站[45]、维基百科和新闻文章[29]中收集的非隐私政策内容。我们从文本中提取了uni-grams和bi-grams的TF-IDF（首先将文本转换为小写，然后删除所有的英文停顿词），然后使用TF-IDF特征来训练SVM分类器（使用 "sigmoid "核）。使用5倍交叉验证，我们能够获得99.8%的精确度和召回率（精确度也在99.8%左右）。然后我们测试了要求一个或多个权限的技能的隐私政策，因为亚马逊授权这些技能提供隐私政策。该分类器的精确度和召回率分别为99.5%和98.5%。


# DISCUSSION
虽然亚马逊限制了对技能的用户数据的访问，并提出了一些规则，但仍有空间让恶意行为者利用或规避其中的一些规则。自动启用技能减少了本地和第三方技能之间的区别；然而，用户仍然不知道哪个技能在回应他们的查询。这可以使攻击者利用他们与系统建立的信任。基于我们的分析，我们提出以下建议：
1. 技能类型指示器（Skill-Type Indicator.）。技能名称和调用短语不要求是唯一的。这个设计决定是在技能需要通过应用程序手动激活时做出的，在那里用户可以看到描述和开发者的名字。自从亚马逊引入自动启用功能后，用户不太可能知道他们正在互动的技能以及他们的数据是如何被使用的。例如，Alexa可以在与第三方应用程序互动时提供某种形式的视觉或口头指示（例如，灯光或不同的语音模板）。需要进一步的人机交互研究来评估语音助手如何确保用户意识到哪些技能正在被启用。
2. 验证开发者（Validating Developers）。我们已经表明，用任何开发者的名字注册账户都是可能的，甚至是那些知名的公司。这可能会误导用户，甚至被滥用来发动网络钓鱼攻击。为了改善这种情况，亚马逊可以利用开发者信息来验证或标记商标侵权行为。另外，像Google Play商店一样，亚马逊可以显示开发者的详细信息，如联系电子邮件地址或网站，以提高透明度。
3. （反复出现的）后端验证（(Recurring) Backend Validation.）。目前，没有规定验证后端代码是否有变化。一旦技能被批准，开发者可以推送任何代码更新，而不需要进一步验证。虽然我们不期望亚马逊完全解决这个问题，因为后端代码可能会经历多轮更新，但这个威胁需要被承认和理解。亚马逊可以进行潜在的随机重复的后端检查。
4. 隐私政策模板（Privacy Policy Template）。开发者只需要提供一个（有效的）政策链接就可以获得认证并开始收集用户数据。对于政策链接是否传达了用户可能有兴趣了解的所有（或任何）必要信息，没有检查[22]。这个问题可以通过要求开发者填写一个简单的政策模板来解决，该模板将包括收集什么数据，出于什么目的，数据被保留多长时间，以及用户是否可以删除或修改他们的数据。另外，还应该提供一个有效的联系地址。这些要求大多与GDPR和CCPA对公司/开发商的最低要求一致。


#Limitation
首先，虽然我们收集的技能数据是我们所知的最大的，但我们有可能错过了许多技能。然而，鉴于我们已经收集了超过90,194项独特的技能，超过了亚马逊在2019年报告的80,000项技能[24]，我们没有预见到我们报告的数字会有任何重大差异。第二，我们提供了一个保守的下限近似值，以证明绕过权限API的技能的存在，通过利用更复杂的NLP技术，可以进行更全面的估计。我们计划在不久的将来对此进行探索。最后，在确定不同技能抢夺技术的有效性时，我们测试了相对较少的随机技能。一个完全自动化的方法将使我们能够大大扩展我们的测试。然而，开发这样一种完全自动化的方法是一个具有挑战性的问题。












