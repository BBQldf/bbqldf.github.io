---
layout:     post
title:     消息队列如何保证消息不丢失，且只被消费一次
subtitle:   基础知识、扩展学习
date:       2022-08-21
author:     ldf
header-img: img/post-bg-distribute01.png
catalog: true
tags:
    - 分布式基础
    - 消息队列
---

## 消息队列如何保证消息不丢失，且只被消费一次



### 1、 为何消息会丢失？

要想保证消息只被消费一次，那么首先就得要保证消息不丢失。我们先来看看，消息从被写入消息队列，到被消费完成，这整个链路上会有哪些地方可能会导致消息丢失？我们不难看出，其实主要有三个地方：

- 消息从生产者到消息队列的过程。
- 消息在消息队列存储的过程。
- 消息在被消费的过程。

#### 1.1 消息在写到消息队列的过程中丢失

消息生产者一般就是业务系统，消息队列是单独部署了在独立的[服务器](https://cloud.tencent.com/product/cvm?from=10680)上的，所以业务服务器和消息队列服务器可能会出现网络抖动，当出现了网络抖动，消息就会丢失。

一般这种情况，我们可以采用消息重传的方案，即当我们发现发送的消息超时后，我们就重新发送一次，但是不能一直无限制的重传消息。按照经验来说，如果不是消息队列本身故障，或者是网络断开了，一般重试个 2 到 3 次就行了。

但是，这种方案就有可能造成消息的重复，这样就会导致消费者消费到重复的消息。例如，消息发送到消息队列中，但是由于消息队列处理消息较慢或者网络抖动，这个时候，其实消息是写入成功的，但是对于生产端就认为超时了，那么生产者就会重传当前消息，则会出现消息重复。对于我们上面案例中，就是用户会收到两个红包。

#### 1.2 消息在消息队列中丢失

> 那就从消息队列本身的容灾性去考虑

即使消息发送到了消息队列，消息也不会万无一失，还是会面临丢失的风险。

我们以 Kafka 为例，消息在Kafka 中是存储在本地磁盘上的， 为了减少消息存储对磁盘的随机 I/O，

一般我们会将消息写入到操作系统的 Page Cache 中，然后在合适的时间将消息刷新到磁盘上。

例如，Kafka 可以配置当达到某一时间间隔，或者累积一定的消息数量的时候再刷盘，也就是所谓的**异步刷盘**。

不过，如果发生机器掉电或者机器异常重启，那么 Page Cache 中还没有来得及刷盘的消息就会丢失了。那么怎么解决呢？你可能会把刷盘的间隔设置很短，或者设置累积一条消息就就刷盘，但这样频繁刷盘会对性能有比较大的影响，而且从经验来看，出现机器宕机或者掉电的几率也不高，所以我不建议你这样做。

如果你的电商系统对消息丢失的容忍度很低，那么你可以考虑**以集群方式部署 Kafka 服务，通过部署多个副本备份数据，保证消息尽量不丢失**。

**那么它是怎么实现的呢**？Kafka 集群中有一个 Leader 负责消息的写入和消费，可以有多个 Follower 负责数据的备份。Follower 中有一个特殊的集合叫做 ISR（in-sync replicas），当 Leader 故障时，新选举出来的 Leader 会从 ISR 中选择，默认 Leader 的数据会异步地复制给 Follower，这样在 Leader 发生掉电或者宕机时，Kafka 会从 Follower 中消费消息，减少消息丢失的可能。

由于默认消息是异步地从 Leader 复制到 Follower 的，所以一旦 Leader 宕机，那些还没有来得及复制到 Follower 的消息还是会丢失。为了解决这个问题，Kafka 为生产者提供一个选项叫做“acks”，当这个选项被设置为“all”时，生产者发送的每一条消息除了发给 Leader 外还会发给所有的 ISR，并且必须得到 Leader 和所有 ISR 的确认后才被认为发送成功。这样，只有 Leader 和所有的 ISR 都挂了，消息才会丢失。

#### 1.3 在消费的过程中存在消息丢失的可能

> 这里其实比较难解决，让消费者确认自己使用完了数据在确认的方式，对性能影响较大，加上这里是非关键链路，其实不太好做

这里面接收消息和处理消息的过程都可能会发生异常或者失败，比如说，消息接收时网络发生抖动，导致消息并没有被正确的接收到；处理消息时可能发生一些业务的异常导致处理流程未执行完成，这时如果更新消费进度，那么这条失败的消息就永远不会被处理了，也可以认为是丢失了。

**所以，**在这里你需要注意的是，一定要等到消息接收和处理完成后才能更新消费进度，但是这也会造成消息重复的问题，比方说某一条消息在处理之后，消费者恰好宕机了，那么因为没有更新消费进度，所以当这个消费者重启之后，还会重复地消费这条消息。

**为了避免消息丢失，我们需要付出两方面的代价：一方面是性能的损耗；一方面可能造成消息重复消费。**

### 2、如何保证消息只被消费一次

#### 2.1 在生产过程中增加消息幂等性的保证

在消息生产过程中，在 Kafka0.11 版本和 Pulsar 中都支持“producer idempotency”的特性，翻译过来就是生产过程的幂等性，这种特性保证消息虽然可能在生产端产生重复，但是最终在消息队列存储时只会存储一份。

它的做法是给每一个生产者一个唯一的 ID，并且为生产的每一条消息赋予一个唯一 ID，消息队列的服务端会存储 < 生产者 ID，最后一条消息 ID> 的映射。当某一个生产者产生新的消息时，消息队列服务端会比对消息 ID 是否与存储的最后一条 ID 一致，如果一致，就认为是重复的消息，服务端会自动丢弃。



#### 2.2 在消费过程中增加消息幂等性的保证

你可以看到，无论是生产端的幂等性保证方式，还是消费端通用的幂等性保证方式，它们的共同特点都是为每一个消息生成一个唯一的 ID，然后在使用这个消息的时候，先比对这个 ID 是否已经存在，如果存在，则认为消息已经被使用过。所以这种方式是一种标准的实现幂等的方式，你在项目之中可以拿来直接使用

如果消息在处理之后，还没有来得及写入数据库，消费者宕机了重启之后发现数据库中并没有这条消息，还是会重复执行两次消费逻辑，这时你就需要引入**事务机制**，保证消息处理和写入数据库必须同时成功或者同时失败，但是这样消息处理的成本就更高了，所以，如果对于消息重复没有特别严格的要求，可以直接使用这种通用的方案，而不考虑引入事务。

具体的操作方式是这样的：你给每个人的账号数据中增加一个版本号的字段，在生产消息时先查询这个账户的**版本号**，并且将版本号连同消息一起发送给消息队列。消费端在拿到消息和版本号后，在执行更新账户金额 SQL 的时候带上版本号