---
layout:     post
title:     CGo学习-性能问题重定位
subtitle:   扩展学习
date:       2022-08-29
author:     ldf
header-img: img/post-bg-cgo01.png
catalog: true
tags:
    - CGo
    - 开发技巧
    - 跨语言编译
---


## 1、Cgo性能问题重定位

### 1.1 问题背景：

上周发现一个问题，在08-25的20:43分之后，把.133的机器改为Cgo1000之后，数据被完全消费，出现队列为空的情况。

![](https://raw.githubusercontent.com/BBQldf/PicGotest/master/20220826020148.png)

当时分析情况是，

```
为什么在某一次上线队列中数据量较少情况出现之后，Cgo能一直触发拿空的情景？按道理，数据量较少情况出现之后数据量马上回到了正常水平，按道理应该是读取不过来（如果能读取过来，就不需要数据量较少的情况来触发了）

为什么Cgo10、Cgo100、Cgo1000都能触发上面的情况，但是Cgo1次（30.49.74.64）却不能触发（看监控是20:30-22:30确实网络活动很稳定)；这到底是Cgo造成的，还是网络因素造成的。
```

<font color='red'>把问题定位给了网络问题。这里的分析是错误的</font>

重新看一下监控，可以发现，**在21:35的时候队列为空是因为机器服务刚刚重启，上线队列被初始化导致的。**

![](https://raw.githubusercontent.com/BBQldf/PicGotest/master/20220829161837.png)

所以这个时候队列为空是合理的。

那为什么cgo1次调用在20:27分重启之后并没有出现读取队列为空的情况（已经确定27分的时候上线队列被初始化）：

![](https://raw.githubusercontent.com/BBQldf/PicGotest/master/20220829162301.png)

而且针对测试号码的上线情况的上报`filtered data count`与其他机器的上报是一致的。（视图看起来这个指标，几个机器都是相同的）

问题：

1. 为什么Cgo1次的调用会有问题？
2. 并且视图上看到23:23分的时候服务被重新启动了一段时间，而这段时间用的是哪个镜像版本？（这个应该是从本地打包了一个二进制上去运行了，无法定位到）

### 1.2 问题复现

先找到当时的commit，

![](https://raw.githubusercontent.com/BBQldf/PicGotest/master/20220829160449.png)

然后在蓝盾流水线上找到对应的镜像版本：

- V31加火焰图cgo1
- V32加火焰图cgo10
- V33加火焰图cgo100
- V34加火焰图cgo1000

重新在11.142.163.133机器上进行部署。

#### 1.2.1、先部署v31

指标分析测试效果：

- 16:07分服务重新部署后，`queryGet Empty`指标一直为空；反序列化的数据量一直为7.5M左右波动；（16:18：7047840/min）
- 16:29分lamlmz操作测试机器上线，并且被捕捉，`filtered data count`指标+1
- 16:33分defend操作测试机器上线，被捕捉到，16:34分`filtered data count`指标+1；<font color='red'>看起来有延时</font>

对比这台机器上面loginClient的数据量变化：

- 16:06分队列数据大量下降（1350780/min），下一分钟数据恢复正常至8M左右波动（16:18：8076254/min）

去机器上看一下日志，是否能及时打印出来：

```
2022-08-29 16:28:10.217 DEBUG   service/user_distributor.go:70  req:push_uin:1317494075  app_id:1001  msf_app_type:537131064  msf_client_type:109
2022-08-29 16:33:35.276 DEBUG   service/user_distributor.go:70  req:push_uin:1317494075  app_id:1001  msf_app_type:537131064  msf_client_type:109
2022-08-29 16:36:58.465 DEBUG   service/user_distributor.go:70  req:push_uin:1317494075  app_id:1001  msf_app_type:537121996  msf_client_type:83714
2022-08-29 16:38:34.160 DEBUG   service/user_distributor.go:70  req:push_uin:1317494075  app_id:1001  msf_app_type:537131064  msf_client_type:109
2022-08-29 16:39:40.316 DEBUG   service/user_distributor.go:70  req:push_uin:1317494075  app_id:1001  msf_app_type:537121996  msf_client_type:83714
2022-08-29 16:45:02.102 DEBUG   service/user_distributor.go:70  req:push_uin:1317494075  app_id:1001  msf_app_type:537131064  msf_client_type:109
2022-08-29 16:46:37.309 DEBUG   service/user_distributor.go:70  req:push_uin:1317494075  app_id:1001  msf_app_type:537131064  msf_client_type:109
2022-08-29 16:51:52.171 DEBUG   service/user_distributor.go:70  req:push_uin:1317494075  app_id:1001  msf_app_type:537131064  msf_client_type:109
```

与正常机器的打印结果进行对比：

```
[2022-08-29 16:27:51] DEBUG: uinInfo|1317494075|1001|connPtl=0|msfAppType=537131064|msfClientType=109
[2022-08-29 16:27:51] DEBUG: uinInfo|1317494075|1001|connPtl=0|msfAppType=537131064|msfClientType=109|isTestEnvANDdye=true
[2022-08-29 16:27:51] DEBUG: Send heartbeat: 94
[2022-08-29 16:27:55] DEBUG: Headbeat timeout: 0
[2022-08-29 16:31:09] DEBUG: uinInfo|1317494075|1001|connPtl=0|msfAppType=537131064|msfClientType=109
[2022-08-29 16:31:09] DEBUG: uinInfo|1317494075|1001|connPtl=0|msfAppType=537131064|msfClientType=109|isTestEnvANDdye=true
[2022-08-29 16:31:09] DEBUG: Send heartbeat: 95
[2022-08-29 16:31:12] DEBUG: Headbeat timeout: 0
[2022-08-29 16:33:17] DEBUG: uinInfo|1317494075|1001|connPtl=0|msfAppType=537131064|msfClientType=109
[2022-08-29 16:33:17] DEBUG: uinInfo|1317494075|1001|connPtl=0|msfAppType=537131064|msfClientType=109|isTestEnvANDdye=true
[2022-08-29 16:33:17] DEBUG: Send heartbeat: 96
[2022-08-29 16:33:20] DEBUG: Headbeat timeout: 0
[2022-08-29 16:36:40] DEBUG: uinInfo|1317494075|1001|connPtl=0|msfAppType=537121996|msfClientType=83714
[2022-08-29 16:36:40] DEBUG: uinInfo|1317494075|1001|connPtl=0|msfAppType=537121996|msfClientType=83714|isTestEnvANDdye=true
[2022-08-29 16:36:40] DEBUG: Send heartbeat: 97
[2022-08-29 16:36:43] DEBUG: Headbeat timeout: 0
[2022-08-29 16:38:16] DEBUG: uinInfo|1317494075|1001|connPtl=0|msfAppType=537131064|msfClientType=109
[2022-08-29 16:38:16] DEBUG: uinInfo|1317494075|1001|connPtl=0|msfAppType=537131064|msfClientType=109|isTestEnvANDdye=true
[2022-08-29 16:38:16] DEBUG: Send heartbeat: 98
[2022-08-29 16:38:19] DEBUG: Headbeat timeout: 0
[2022-08-29 16:38:36] DEBUG: uinInfo|1317494075|1001|connPtl=0|msfAppType=537121996|msfClientType=83714
[2022-08-29 16:38:36] DEBUG: uinInfo|1317494075|1001|connPtl=0|msfAppType=537121996|msfClientType=83714|isTestEnvANDdye=true
[2022-08-29 16:38:36] DEBUG: Send heartbeat: 99
[2022-08-29 16:38:39] DEBUG: Headbeat timeout: 0
[2022-08-29 16:39:04] DEBUG: uinInfo|1317494075|1001|connPtl=0|msfAppType=537121996|msfClientType=83714
[2022-08-29 16:39:04] DEBUG: uinInfo|1317494075|1001|connPtl=0|msfAppType=537121996|msfClientType=83714|isTestEnvANDdye=true
[2022-08-29 16:39:04] DEBUG: Send heartbeat: 100
[2022-08-29 16:39:07] DEBUG: Headbeat timeout: 0
```

结果分析：

1. **Cgo1次调用确实存在性能问题**，它从队列中读取数据的速度很慢，导致测试机器上线后，在队列里面，需要过**几十秒**（37s）才能被读到，**甚至有被丢弃**的数据（比如，正常机器在16:31:09有一次上线数据，但是Cgo1次调用中缺失）。这也侧面反映了loginClient的数据是维持在一个队列上的，queryGet是按顺序去消费

看一下原本的distributor代码：

```
    // 多进程处理
    // 从1开始，创建3个子进程，加上父进程共4个，每个进程处理uin低两位特定的值。
    // 低两位组合：00 | 01 | 10 | 11
    // 不建议加太多进程，需要考虑login_client（也是多进程模式）也要占用到很大比例的cpu负载。
    uint8_t low_two_bit = 0;
    for (int i = 1; i < 4; ++i) {
        pid_t pid = fork();
        if (pid == -1) {
            cerr << "Fork failed." << endl;
            return -3;
        } else if (pid == 0) {
            low_two_bit = i;
            prctl(PR_SET_PDEATHSIG, SIGKILL); // 父进程退出，子进程也退出
            break;
        }
    }
   for (;;) {
        bool hasLegalData = false;
        unsigned long long uin = 0;
        int loginBasicAppId = 0;

        unsigned int connPtl = 0;
        unsigned int msfAppType = 0;
        unsigned int msfClientType = 0;

        LoginRecord lrcd;
        int lres = LoginQuery_Get(lrcd);
        if (lres == 0) {
            if ((lrcd.basic().uin() & 0x3) != low_two_bit) { // 比使用取mod的方式高效
                continue;
            }
            int ret = DoFreqLimit(conf);
            if (ret != 0) {
                continue;
            }
            uin = lrcd.basic().uin();
            attri_api_by_uin(uin, 386811, 2151898, 1);  // 386811 分发_从队列拉到uin
            loginBasicAppId = lrcd.basic().app_id();
            if (lrcd.basic().type() == LOGIN_RECORD_BASIC_TYPE_ONLINE ||
                lrcd.basic().type() == LOGIN_RECORD_BASIC_TYPE_MSFPUSHTOONLINE) {
                if ((loginBasicAppId == APPID_PCQQ || loginBasicAppId == APPID_PCEIM) && lrcd.has_conn_fields()) {
                    connPtl = lrcd.conn_fields().ptl();
                    hasLegalData = true;
                }
                // qcall复用msf_fields
                else if ((loginBasicAppId == APPID_MQQ || loginBasicAppId == APPID_QCALL ||
                          loginBasicAppId == APPID_MEIM) &&
                         lrcd.has_msf_fields()) {
                    msfAppType = lrcd.msf_fields().app_type();
                    msfClientType = lrcd.msf_fields().client_type();
                    hasLegalData = true;

                    if (loginBasicAppId == APPID_QCALL) {
                        Attr_API(2166875, 1);  //分发_QCALL
                    }
                }
            }
```

可见，LoginQuery_Get是可以支持多线程并发读的。



#### 1.2.2 部署v32

分别操作手Q和新MAC上线：

```
2022-08-29 17:13:24.844 DEBUG   service/user_distributor.go:70  req:push_uin:1317494075  app_id:1001  msf_app_type:537131064  msf_client_type:109
2022-08-29 17:13:25.155 DEBUG   loginclient/query_get.go:82     queryGet Empty.
2022-08-29 17:13:25.195 DEBUG   loginclient/query_get.go:82     queryGet Empty.
2022-08-29 17:13:25.360 DEBUG   loginclient/query_get.go:82     queryGet Empty.
2022-08-29 17:13:25.668 DEBUG   loginclient/query_get.go:82     queryGet Empty.
2022-08-29 17:13:26.783 DEBUG   loginclient/query_get.go:82     queryGet Empty.
2022-08-29 17:13:26.938 DEBUG   loginclient/query_get.go:82     queryGet Empty.
2022-08-29 17:13:27.019 DEBUG   loginclient/query_get.go:82     queryGet Empty.
2022-08-29 17:13:58.636 DEBUG   service/user_distributor.go:70  req:push_uin:1317494075  app_id:1001  msf_app_type:537121996  msf_client_type:83714
```

**能够实时打印，**且有大量的`queryGet Empty`打印出现，说明队列被消费完了。



#### 1.2.3 部署v33

操作手Q上线：

```
2022-08-29 17:23:34.931 DEBUG   service/user_distributor.go:70  req:push_uin:1317494075 app_id:1001 msf_app_type:537131064 msf_client_type:109
2022-08-29 17:23:35.041 DEBUG   loginclient/query_get.go:82     queryGet Empty.
2022-08-29 17:23:35.271 DEBUG   loginclient/query_get.go:82     queryGet Empty.
2022-08-29 17:23:35.748 DEBUG   loginclient/query_get.go:82     queryGet Empty.
```

**能够实时打印，**且有大量的`queryGet Empty`打印出现，说明队列被消费完了。



#### 1.2.3 部署v34

操作手Q上线：

```
2022-08-29 18:24:21.502 DEBUG   loginclient/query_get.go:82     queryGet Empty.
2022-08-29 18:24:22.631 DEBUG   loginclient/query_get.go:82     queryGet Empty.
2022-08-29 18:24:22.696 DEBUG   loginclient/query_get.go:82     queryGet Empty.
2022-08-29 18:24:22.785 DEBUG   service/user_distributor.go:70  req:push_uin:1317494075 app_id:1001 msf_app_type:537131064 msf_client_type:109
2022-08-29 18:24:43.233 DEBUG   loginclient/query_get.go:82     queryGet Empty.
2022-08-29 18:24:43.305 DEBUG   loginclient/query_get.go:82     queryGet Empty.
2022-08-29 18:24:43.558 DEBUG   service/user_distributor.go:70  req:push_uin:1317494075 app_id:1001 msf_app_type:537131064 msf_client_type:109
```

**能够实时打印，**且有大量的`queryGet Empty`打印出现，说明队列被消费完了。



### 1.3 问题分析

先看一下这一段时间内007上的监控变化情况：

![](https://raw.githubusercontent.com/BBQldf/PicGotest/master/20220829193144.png)

看一下这一段时间内（部署不同的镜像）机器的负载变化情况：

![](https://raw.githubusercontent.com/BBQldf/PicGotest/master/20220829193448.png)

发现16核的机器，在Cgo次数上升的时候，性能有些微下降。

针对这一现象，我们利用8核的机器重新部署一下cgo1000的情况：

- 日志打印：

```
2022-08-29 19:40:39.717 INFO    server/service.go:156   process:988, trpc service:trpc.qqrtc.qq_av_login_push.LoginPush launch success, tcp,udp:11.142.163.133:8000, serving ...
2022-08-29 19:45:04.562 INFO    service/qq_mav_login_push.go:114        receive: user_info:{push_uin:1049668169 app_id:1001 conn_ptl:4363 msf_app_type:537243329 msf_client_type:82434} user_info:{push_uin:2151677913 app_id:1001 conn_ptl:4363 msf_app_type:537243329 msf_client_type:82434} user_info:{push_uin:131494075 app_id:1001 conn_ptl:4363 msf_app_type:537243329 msf_client_type:82434} user_info:{push_uin:1904366113 app_id:1001 conn_ptl:4363 msf_app_type:537243329 msf_client_type:82434} user_info:{push_uin:2289028665 app_id:1001 conn_ptl:4363 msf_app_type:537243329 msf_client_type:82434} user_info:{push_uin:1027391519 app_id:1001 conn_ptl:4363 msf_app_type:537243329 msf_client_type:82434}
2022-08-29 19:45:04.562 DEBUG   service/qq_mav_login_push.go:120        selectedUsers:[0 1 2 3]
2022-08-29 19:45:04.562 DEBUG   service/qq_mav_login_push.go:128        uin:1049668169, modUin:1
2022-08-29 19:45:04.562 INFO    service/qq_mav_login_push.go:131        0-success;<0-error; >0-no rooms:-1
2022-08-29 19:45:04.562 DEBUG   service/qq_mav_login_push.go:128        uin:2151677913, modUin:1
2022-08-29 19:45:04.562 INFO    service/qq_mav_login_push.go:131        0-success;<0-error; >0-no rooms:-1
2022-08-29 19:45:04.562 DEBUG   service/qq_mav_login_push.go:128        uin:131494075, modUin:3
2022-08-29 19:45:04.563 INFO    service/qq_mav_login_push.go:131        0-success;<0-error; >0-no rooms:-1
2022-08-29 19:45:04.563 DEBUG   service/qq_mav_login_push.go:128        uin:1904366113, modUin:1
2022-08-29 19:45:04.565 INFO    service/qq_mav_login_push.go:131        0-success;<0-error; >0-no rooms:-1
2022-08-29 19:45:04.565 DEBUG   service/qq_mav_login_push.go:128        uin:2289028665, modUin:1
2022-08-29 19:45:04.565 INFO    service/qq_mav_login_push.go:131        0-success;<0-error; >0-no rooms:-1
2022-08-29 19:45:04.565 DEBUG   service/qq_mav_login_push.go:128        uin:1027391519, modUin:3
2022-08-29 19:45:04.565 INFO    service/qq_mav_login_push.go:131        0-success;<0-error; >0-no rooms:-1

2022-08-29 20:07:01.119 DEBUG   service/user_distributor.go:70  req:push_uin:1317494075 app_id:1001 msf_app_type:537131064 msf_client_type:109
2022-08-29 20:10:39.238 DEBUG   service/user_distributor.go:70  req:push_uin:1317494075 app_id:1001 msf_app_type:537131064 msf_client_type:109
```

虽然能够打印出来上线事件，但是响应时间较慢，对比老的机器（实时）：

```
[2022-08-29 20:05:04] DEBUG: Send heartbeat: 17
[2022-08-29 20:05:04] DEBUG: Recv heartbeat: 17
[2022-08-29 20:06:44] DEBUG: uinInfo|1317494075|1001|connPtl=0|msfAppType=537131064|msfClientType=109
[2022-08-29 20:06:44] DEBUG: uinInfo|1317494075|1001|connPtl=0|msfAppType=537131064|msfClientType=109|isTestEnvANDdye=true

[2022-08-29 20:10:22] DEBUG: uinInfo|1317494075|1001|connPtl=0|msfAppType=537131064|msfClientType=109
[2022-08-29 20:10:22] DEBUG: uinInfo|1317494075|1001|connPtl=0|msfAppType=537131064|msfClientType=109|isTestEnvANDdye=true
[2022-08-29 20:10:22] DEBUG: Send heartbeat: 6
[2022-08-29 20:10:22] DEBUG: Recv heartbeat: 6
```

慢了30s。

stke机器负载：

```
Threads: 141 total,   4 running, 134 sleeping,   3 stopped,   0 zombie
%Cpu0  : 27.9 us, 10.0 sy,  0.0 ni, 56.1 id,  0.0 wa,  0.0 hi,  6.1 si,  0.0 st
%Cpu1  : 27.0 us,  9.2 sy,  0.0 ni, 58.9 id,  0.0 wa,  0.0 hi,  5.0 si,  0.0 st
%Cpu2  : 38.8 us,  7.2 sy,  0.0 ni, 54.0 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st
%Cpu3  : 47.3 us,  5.8 sy,  0.0 ni, 46.9 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st
%Cpu4  : 26.1 us,  8.8 sy,  0.0 ni, 48.2 id,  0.0 wa,  0.0 hi, 16.9 si,  0.0 st
%Cpu5  : 34.9 us,  8.3 sy,  0.0 ni, 56.4 id,  0.0 wa,  0.0 hi,  0.3 si,  0.0 st
%Cpu6  : 34.0 us,  8.3 sy,  0.0 ni, 57.6 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st
%Cpu7  : 34.8 us,  6.8 sy,  0.0 ni, 42.4 id,  0.0 wa,  0.0 hi, 15.9 si,  0.0 st
KiB Mem : 65851036 total, 63183260 free,   924348 used,  1743428 buff/cache
KiB Swap:        0 total,        0 free,        0 used. 63325724 avail Mem 

    PID USER      PR  NI    VIRT    RES    SHR S %CPU %MEM     TIME+ COMMAND                                                                                                                                                      
   1190 root      20   0  183900 158784 158184 R 60.3  0.2  19:01.26 login_recv_clie
   1166 root      20   0  183912 159200 158592 S 52.7  0.2  16:20.59 login_recv_clie
   1189 root      20   0  183900 158708 158108 S 45.0  0.2  14:12.91 login_recv_clie
   1188 root      20   0  183900 158856 158256 S 40.7  0.2  12:40.51 login_recv_clie
   1165 root      20   0  416436 391628 391328 R 28.0  0.6   8:53.96 login_recv_clie
   1172 root      20   0 2267624 510396 334508 S 25.3  0.8   4:35.95 qq_login_push
    988 root      20   0 2267624 510396 334508 S 21.0  0.8   3:53.97 qq_login_push
   1176 root      20   0 2267624 510396 334508 S 17.7  0.8   4:34.35 qq_login_push
   1092 root      20   0 2267624 510396 334508 S 16.0  0.8   5:08.00 qq_login_push
   1234 root      20   0 2267624 510396 334508 R 15.3  0.8   4:45.34 qq_login_push
   1228 root      20   0 2267624 510396 334508 S 14.7  0.8   5:11.66 qq_login_push
   4509 root      20   0 2267624 510396 334508 S 14.7  0.8   4:00.47 qq_login_push
   1177 root      20   0 2267624 510396 334508 S 13.3  0.8   5:06.75 qq_login_push
   1233 root      20   0 2267624 510396 334508 S 12.7  0.8   4:59.72 qq_login_push
   1235 root      20   0 2267624 510396 334508 S  9.7  0.8   4:40.18 qq_login_push
    864 root      20   0 1951492  32444   7884 S  1.3  0.0   0:26.63 atta_clients
    865 root      20   0 1951492  32444   7884 S  1.3  0.0   0:26.63 atta_clients
    866 root      20   0 1951492  32444   7884 S  1.0  0.0   0:16.97 atta_dispatcher
   1229 root      20   0 1951492  32444   7884 S  1.0  0.0   0:14.85 atta_worker
   1231 root      20   0 1951492  32444   7884 S  1.0  0.0   0:14.96 atta_worker
    749 root      20   0  708464  23792   6988 S  1.0  0.0   0:17.40 time_ticker
   1086 root      20   0 2267624 510396 334508 S  1.0  0.8   0:21.32 qq_login_push
    420 user_00   20   0   10936   1808   1348 S  0.7  0.0   0:04.27 l5_config
    444 root      20   0  729416  28372  17760 S  0.7  0.0   0:02.88 configd
    630 root      20   0  735408  45976  18924 S  0.7  0.1   0:03.80 tencentcloud_cl
    756 root      20   0 1951492  32444   7884 S  0.7  0.0   0:16.65 time_ticker
    859 root      20   0 1951492  32444   7884 S  0.7  0.0   0:14.98 atta_worker
    871 root      20   0 1951492  32444   7884 S  0.7  0.0   0:14.67 atta_server
    872 root      20   0 1951492  32444   7884 S  0.7  0.0   0:14.98 atta_worker
    922 root      20   0 1951492  32444   7884 S  0.7  0.0   0:14.92 atta_worker
   1221 root      20   0 1951492  32444   7884 S  0.7  0.0   0:14.93 atta_worker     
```

- 看一下stke上的监控：

![](https://raw.githubusercontent.com/BBQldf/PicGotest/master/20220829202549.png)

发现负载上升到了60%，CPU核数开销并没有波动

- 007上监控：

![](https://raw.githubusercontent.com/BBQldf/PicGotest/master/20220829202814.png)

可以看到，在最初数据量不多的情况下，还有2次`queryGet empty`的上报，但是后面就没有了，这一点也与日志是对应上的。

在调用量上面看，似乎和之前16核的机器，**就差了一点点数据量的差别。**



### 1.4 问题总结

所以Cgo调用的性能问题，在一开始测试的时候通过下沉数据调用到C代码的方式就已经解决了。但是周五的分析中出现了偏差，误以为队列数据量变少是机器网络波动导致，进而导致Cgo的性能分析没有头绪。

- 其实队列数据量变少是一个正常现象，是因为服务重新部署后，执行了`AvLoginQueryInit() `，将队列初始化了。

所以，Cgo10、Cgo100、Cgo1000次调用能够大量上报`queryGet Empty`是正常的。

<font color='red'>两种情况总结：</font>

1. **16核机器，Cgo1次调用获取数据不全缺失是由Cgo性能问题导致的；**
2. **8 核机器，Cgo1000次调用获取数据不全是机器性能导致的；**



## 2、老代码将客户端类型和版本写死问题

### 2.1 项目背景

老的上线推送服务的分发器和上线推送服务本身都有一段hardcode的逻辑，用来判断用户登录时的机型和版本号。

- 分发器

```
        if (loginBasicAppId == APPID_PCQQ || loginBasicAppId == APPID_PCEIM) {
            if (connPtl >= conf.pcSupportVersion) {
                return true;
            } else {
                return false;
            }
        }
		//查手q appid:http://mqq.server.com/web_mqq_admin/web/index.jsp
        if ((msfClientType == MOBILE_CLINET_ANDROID && msfAppType > 537037772) ||
            (isIphone(msfClientType) && (msfAppType >= 537037538 && msfAppType <= 537037542)) ||
            (isIphone(msfClientType) && msfAppType > 537037887) ||
            (msfClientType == MOBILE_CLINET_ANDROID && msfAppType == 537035451) ||
            (msfClientType == MOBILE_CLINET_ANDROID && (msfAppType >= 537037734 && msfAppType <= 537037744)) ||
            (msfClientType == MOBILE_CLINET_IPADQQ && msfAppType >= 537038740) ||
            (msfClientType == ClientType_MAC && msfAppType >= 537043329) ||
            (msfClientType == ClientType_MAC_New && msfAppType >= 537043329)) {
            return true;
        }
        else if (msfClientType == ClientType_TIM_Android && msfAppType > 537037772) {
            return true;
        }
        // TIM2.0 ios(77826) 和ios MQQ对齐
        else if (msfClientType == ClientType_TIM_IPhone && msfAppType > 537037887) {
            return true;
        } else {
            // 新增的msfClientType
            if (msfClientType > ClientType_Mobile_IPhone11ProMax) {
                Attr_API(35071709, 1);  // 未知类型
                if (g_map_log_count.find(msfClientType) == g_map_log_count.end()) {
                    g_map_log_count[msfClientType] = 0;
                }
                if (g_map_log_count[msfClientType]++ % conf.log_interval == 0) {
                    conf.log << error << "Not surport type. msfClientType: " << msfClientType
                             << ", msfAppType: " << msfAppType;
                    g_map_log_count[msfClientType] = 0;
                }
            }
        }
        return false;
    }
```

上线推送：

```
        //版本过滤，减少初期的请求量
        bool getGroupList = false;
        if (appId == APPID_MQQ && CONF::Instance()->mobileGroupSend0x95 == 1) {
            if (isMobileIphone() || msfClientType == ClientType_TIM_IPhone ||
                msfClientType == ClientType_Desktop_QQNT) {
                // TIM2.0 ios(77826) 和ios MQQ对齐

                getGroupList = msfAppType >= CONF::Instance()->mobileGroup0x95IosBaseVer;
                if (getGroupList && msfAppType >= 537038815 && msfAppType <= 537039365) {
                    //排除掉中间的
                    getGroupList = false;
                }
            } else if (msfClientType == MOBILE_CLINET_ANDROID || msfClientType == ClientType_TIM_Android) {
                // TIM2.0 andriod(77570)和andriod MQQ(109)对齐

                getGroupList = msfAppType >= CONF::Instance()->mobileGroup0x95AndBaseVer;
                if (getGroupList && ((msfAppType >= 537038931 && msfAppType <= 537039378) ||
                                     (msfAppType >= 537039475 && msfAppType <= 537039537))) {
                    //排除掉中间的
                    getGroupList = false;
                }
            } else if (msfClientType == ClientType_MAC || msfClientType == ClientType_MAC_New ||
                       msfClientType == MOBILE_CLINET_IPADQQ) {
                getGroupList = msfAppType >= CONF::Instance()->MacGroup0x95BaseVer;
            }
        } else if (appId == APPID_PCQQ && CONF::Instance()->pcGroupSend0x95 == 1) {
            getGroupList = connPtl >= CONF::Instance()->pcGroup0x95BaseVer;
        }
```

针对上线推送这里的逻辑，其实还是有量的，说明还是有一些低版本的QQ用户在上线。

### 2.2 项目实现

**与hunting沟通以后，决定把用户机型MsfClientType做成远程配置化，用户版本MsfAppTpye还是在代码中hardcode，维持老代码逻辑。**

通过上面的逻辑，可以把上线的数据分为2个大类，5个小类（MQQ对应1~4类，PCQQ对应5类）：

MQQ的类型：

```
APPID_MQQ = 1001            //MQQ AppId
```

1. Android的类型

```
// TIM2.0 andriod(77570)和andriod MQQ(109)对齐
MOBILE_CLINET_ANDROID = 109,
ClientType_TIM_Android = 77570,            // 0x012F02 (1 << 16) | (47 << 8) | (2 << 0)
```

2. Mac的类型

```
ClientType_MAC = 66818,                    // 0x10502  (1 << 16) | (5 << 8) | (2 << 0);
ClientType_MAC_New = 66831,                // 0x1050F (1 << 16) | (5 << 8) | (15 << 0);
MOBILE_CLINET_IPADQQ = 108,
```

3. iPhone的类型

```
MOBILE_CLINET_IPHONE = 110,  // iphone qq
ClientType_Mobile_IPhone6s = 75266,        // 0x012602(1 << 16) | (38 << 8) | (2 << 0);
ClientType_Mobile_IPhone6sPlus = 75522,    // 0x012702(1 << 16) | (39 << 8) | (2 << 0);
ClientType_Mobile_IPhoneSE = 76034,        // 0x012902(1 << 16) | (41 << 8) | (2 << 0);
ClientType_Mobile_IPhone7 = 76802,         // 0x012C02 (1 << 16) | (44 << 8) | (2 << 0)
ClientType_Mobile_IPhone7Plus = 77058,     // 0x012D02 (1 << 16) | (45 << 8) | (2 << 0)
ClientType_TIM_PC = 77313,                 // 0x012E01 (1 << 16) | (46 << 8) | (1 << 0)
ClientType_TIM_Android = 77570,            // 0x012F02 (1 << 16) | (47 << 8) | (2 << 0)
ClientType_TIM_IPhone = 77826,             // 0x013002 (1 << 16) | (48 << 8) | (2 << 0)
ClientType_WatchQQ = 78082,                // 0x013102 (1<< 16) | (49 << 8) | (2 << 0)
ClientType_QIM_Android = 78343,            // 0x013207 (1<< 16) | (50<< 8) | (7 << 0)
ClientType_QIM_IPhone = 78342,             // 0x013206 (1<< 16) | (50<< 8) | (6 << 0)
ClientType_Mobile_IPhone8 = 78594,         // 0x013302 (1 << 16) | (51 << 8) | (2 << 0)
ClientType_Mobile_IPhone8Plus = 78850,     // 0x013402 (1 << 16) | (52 << 8) | (2 << 0)
ClientType_Mobile_IPhoneX = 79106,         // 0x013502 (1 << 16) | (53 << 8) | (2 << 0)
ClientType_Mobile_IPhone9 = 79618,         // 0x013702 (1 << 16) | (55 << 8) | (2 << 0)
ClientType_Mobile_IPhoneXs = 79874,        // 0x013802 (1 << 16) | (56 << 8) | (2 << 0)
ClientType_Mobile_IPhoneXsPlus = 80130,    // 0x013902 (1 << 16) | (57 << 8) | (2 << 0)
ClientType_Mobile_IPhone11 = 80386,        // 0x013a02 (1 << 16) | (58 << 8) | (2 << 0)
ClientType_Mobile_IPhone11Pro = 80642,     // 0x013b02 (1 << 16) | (59 << 8) | (2 << 0)
ClientType_Mobile_IPhone11ProMax = 80898,  // 0x013c02 (1 << 16) | (60 << 8) | (2 << 0)
ClientType_Mobile_IPhone12Mini = 81666,    // 0x13F02 (1 << 16) | (63 << 8) | (2 << 0)
ClientType_Mobile_IPhone12 = 81922,        // 0x14002 (1 << 16) | (64 << 8) | (2 << 0)
ClientType_Mobile_IPhone12Pro = 82178,     // 0x14102 (1 << 16) | (65 << 8) | (2 << 0)
ClientType_Mobile_IPhone12ProMax = 82434,   // 0x14202 (1 << 16) | (66 << 8) | (2 << 0)
ClientType_Mobile_IPhone13Mini = 82690,      //0x14302 (1 << 16) | (67 << 8) | (2 << 0)
ClientType_Mobile_IPhone13 = 82946,          //0x14402 (1 << 16) | (68 << 8) | (2 << 0)
ClientType_Mobile_IPhone13Pro = 83202,       //0x14502 (1 << 16) | (69 << 8) | (2 << 0)
ClientType_Mobile_IPhone13ProMax = 83458,     //0x14602 (1 << 16) | (70 << 8) | (2 << 0)
ClientType_Desktop_QQNT = 83714  			  //0x14702 (1 << 16) | (71 << 8) | (2 << 0)


// TIM2.0 ios(77826) 和ios MQQ对齐
ClientType_TIM_IPhone = 77826,             // 0x013002 (1 << 16) | (48 << 8) | (2 << 0)
```

**（注意，新加的桌面版qq延续了iPhone的机型递增属性，这是否合理？）**

4. 额外的类型——TIM2.0

```
    ClientType_TIM_Android = 77570,            // 0x012F02 (1 << 16) | (47 << 8) | (2 << 0)
    ClientType_TIM_IPhone = 77826,             // 0x013002 (1 << 16) | (48 << 8) | (2 << 0)
    ClientType_TIM_PC = 77313,                 // 0x012E01 (1 << 16) | (46 << 8) | (1 << 0)
```

ClientType_TIM_PC没有使用，其他TIM机型和相应的android和iPhone对齐。

5. PC的类型

```
APPID_PCQQ = 1              //PCQQ AppId
```

这样就好理解分发器和上线推送两块的过滤逻辑了：

1、上线推送分发器会先过滤调用（指定版本过滤）

```
//distributorVersionFilter 分发器前置版本过滤逻辑（针对Android,iphone,mac,TIM,PC)
func distributorVersionFilter(ctx context.Context, appId int32, msfClientType, msfAppType, connPtl uint32, conf *filterVersion) bool {
	var isPush bool
	if appId == APPID_MQQ && conf.mobileGroupSend0x95 == 1 {
		//MQQ的判断依据是msfClientType是否大于指定版本
		if (isMobileAndroid(msfClientType) && msfAppType > 537037772) ||
			(isMobileAndroid(msfClientType) && msfAppType == 537035451) ||
			(isMobileAndroid(msfClientType) && (msfAppType >= 537037734 && msfAppType <= 537037744)) ||
			(isMobileIphone(msfClientType) && (msfAppType >= 537037538 && msfAppType <= 537037542)) ||
			(isMobileIphone(msfClientType) && msfAppType > 537037887) ||
			(isMac(msfClientType) && msfAppType >= 537038740) ||
			(isMac(msfClientType) && msfAppType >= 537043329) ||
			(isMac(msfClientType) && msfAppType >= 537043329) {
			return true
		} else { //新增的msfClientType
			metrics.IncrCounter("unknown msfClientType", 1) //当出现这个上报的时候就需要手动添加配置
			log.ErrorContextf(ctx, "ERROR!Not surport msftype.appId:%d, msfClientType: %d, msfAppType:%d;",
				appId, msfClientType, msfAppType)
		}
	} else if appId == APPID_PCQQ && conf.pcGroupSend0x95 == 1 {
		//PCQQ的判断依据是:connPtl大于pcGroup0x95BaseVer
		isPush = connPtl >= conf.pcGroup0x95BaseVer
	}
	return isPush
}

//isMobileIphone 判断是否是IPhone
func isMobileIphone(msfClientType uint32) bool { //手Q客户端类型 Android(109)  iOS(110) iPad(108)
	for _, clientType := range config.GetRainbowConfig().WhiteIphoneMsfClientType {
		if msfClientType == clientType {
			log.DebugContextf(context.TODO(), "msfClientType %d is mobileIPhone", msfClientType)
			return true
		}
	}
	return false
}

//isMac 判断是否是Mac/ipad/MAC_New
func isMac(msfClientType uint32) bool { //手Q客户端类型 Android(109)  iOS(110) iPad(108)
	for _, clientType := range config.GetRainbowConfig().WhiteMacMsfClientType {
		if msfClientType == clientType {
			log.DebugContextf(context.TODO(), "msfClientType %d is Mac", msfClientType)
			return true
		}
	}
	return false
}

//isMobileAndroid 判断是否是Android
func isMobileAndroid(msfClientType uint32) bool { //手Q客户端类型 Android(109)  iOS(110) iPad(108)
	for _, clientType := range config.GetRainbowConfig().WhiteAndroidMsfClientType {
		if msfClientType == clientType {
			log.DebugContextf(context.TODO(), "msfClientType %d is mobileAndroid", msfClientType)
			return true
		}
	}
	return false
}
```

2、 上线推送会再次过滤（低版本过滤）

```
/*
versionFilter 版本过滤;
针对不同类型的客户端类型(msfClientType决定)，过滤低版本的手Q/PCQQ(由msfAppType/connPtl决定),
getGroupList置为false，后续不再通过0x5d5查询群列表
appId:终端类型(PC/MQQ)
msfClientType:客户端类型(IoS/Android/Mac/PC)
msfAppType:版本号
conf:远程预配置的过滤版本
*/
func versionFilter(appId int32, msfClientType, msfAppType, connPtl uint32, conf *filterVersion) bool {
	var getGroupList bool
	if appId == APPID_MQQ && conf.mobileGroupSend0x95 == 1 {
		if isMobileIphone(msfClientType) {
			// TIM2.0 ios(77826)/ios MQQ 需要msfAppType大于mobileGroup0x95IosBaseVer
			getGroupList = msfAppType >= conf.mobileGroup0x95IosBaseVer
			if getGroupList && msfAppType >= 537038815 && msfAppType <= 537039365 {
				getGroupList = false
			}
		} else if isMobileAndroid(msfClientType) {
			// TIM2.0 andriod(77570)/andriod MQQ(109)需要msfAppType大于mobileGroup0x95AndBaseVer
			getGroupList = msfAppType >= conf.mobileGroup0x95AndBaseVer
			if getGroupList && ((msfAppType >= 537038931 && msfAppType <= 537039378) ||
				(msfAppType >= 537039475 && msfAppType <= 537039537)) {
				getGroupList = false
			}
		} else if isMac(msfClientType) {
			//MAC QQ 的AppType需要大于MacGroup0x95BaseVer
			getGroupList = msfAppType >= conf.MacGroup0x95BaseVer
		}
	} else if appId == APPID_PCQQ && conf.pcGroupSend0x95 == 1 {
		//PCQQ需要connPtl大于pcGroup0x95BaseVer
		getGroupList = connPtl >= conf.pcGroup0x95BaseVer
	}
	if !getGroupList {
		metrics.IncrCounter("old MQQ query request count", 1) // push_手Q旧版过滤调查询群列表
	}
	return getGroupList
}
```



















